{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = '0.3.17'\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "#import argparse\n",
    "import visdom\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pprint\n",
    "from easydict import EasyDict as edict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from world import cfg, create_logger, AverageMeter, accuracy\n",
    "\n",
    "\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "\n",
    "opt = edict()\n",
    "\n",
    "opt.MODEL = edict()\n",
    "opt.MODEL.ARCH = 'resnet50'\n",
    "opt.MODEL.PRETRAINED = True\n",
    "opt.MODEL.IMAGE_SIZE = 256\n",
    "opt.MODEL.INPUT_SIZE = 224 # crop size\n",
    "\n",
    "opt.EXPERIMENT = edict()\n",
    "opt.EXPERIMENT.CODENAME = '2B'\n",
    "opt.EXPERIMENT.TASK = 'test'\n",
    "opt.EXPERIMENT.DIR = osp.join(cfg.EXPERIMENT_DIR, opt.EXPERIMENT.CODENAME)\n",
    "\n",
    "opt.LOG = edict()\n",
    "opt.LOG.LOG_FILE = osp.join(opt.EXPERIMENT.DIR, 'log_{}.txt'.format(opt.EXPERIMENT.TASK))\n",
    "\n",
    "opt.TEST = edict()\n",
    "opt.TEST.CHECKPOINT = '/home/guang/Projects/Kaggle/landmark-recognition-challenge/experiments/2B/resnet50_[8]_96.07.pk'\n",
    "opt.TEST.WORKERS = 8\n",
    "opt.TEST.BATCH_SIZE = 32\n",
    "opt.TEST.OUTPUT = osp.join(opt.EXPERIMENT.DIR, 'pred.npz')\n",
    "\n",
    "opt.DATASET = 'recognition'\n",
    "\n",
    "opt.VISDOM = edict()\n",
    "opt.VISDOM.PORT = 8097\n",
    "opt.VISDOM.ENV = '[' + opt.DATASET + ']' + opt.EXPERIMENT.CODENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not osp.exists(opt.EXPERIMENT.DIR):\n",
    "    os.makedirs(opt.EXPERIMENT.DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "logger = create_logger(opt.LOG.LOG_FILE)\n",
    "logger.info('\\n\\nOptions:')\n",
    "logger.info(pprint.pformat(opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "DATA_INFO = cfg.DATASETS[opt.DATASET.upper()]\n",
    "    \n",
    "# Data-loader of testing set\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((opt.MODEL.IMAGE_SIZE)),\n",
    "    transforms.CenterCrop(opt.MODEL.INPUT_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                          std = [ 0.229, 0.224, 0.225 ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "    \n",
    "#train_dataset = datasets.ImageFolder(DATA_INFO.TRAIN_DIR, transform_test)      \n",
    "test_dataset = datasets.ImageFolder(DATA_INFO.TEST_DIR, transform_test)  \n",
    "logger.info('{} images are found for test'.format(len(test_dataset.imgs)))\n",
    "\n",
    "test_list = pd.read_csv(osp.join(DATA_INFO.ROOT_DIR, 'test.csv'))\n",
    "test_list = test_list['id']\n",
    "logger.info('{} images are expected for test'.format(len(test_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=opt.TEST.BATCH_SIZE, shuffle=False, num_workers=opt.TEST.WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create model\n",
    "if opt.MODEL.PRETRAINED:\n",
    "    logger.info(\"=> using pre-trained model '{}'\".format(opt.MODEL.ARCH ))\n",
    "    model = models.__dict__[opt.MODEL.ARCH](pretrained=True)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "#    logger.info(\"=> creating model '{}'\".format(args.arch))\n",
    "#    model = models.__dict__[opt.MODEL.ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "if opt.MODEL.ARCH.startswith('resnet'):\n",
    "    assert(opt.MODEL.INPUT_SIZE % 32 == 0)\n",
    "    model.avgpool = nn.AvgPool2d(opt.MODEL.INPUT_SIZE // 32, stride=1)\n",
    "    #model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, DATA_INFO.NUM_CLASSES)\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "last_checkpoint = torch.load(opt.TEST.CHECKPOINT)\n",
    "assert(last_checkpoint['arch']==opt.MODEL.ARCH)\n",
    "model.module.load_state_dict(last_checkpoint['state_dict'])\n",
    "#optimizer.load_state_dict(last_checkpoint['optimizer'])\n",
    "logger.info(\"Checkpoint '{}' was loaded.\".format(opt.TEST.CHECKPOINT))\n",
    "\n",
    "last_epoch = last_checkpoint['epoch']\n",
    "    #logger.info(\"Training will be resumed from Epoch {}\".format(last_checkpoint['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vis = visdom.Visdom(port=opt.VISDOM.PORT)\n",
    "vis.close()\n",
    "vis.text('HELLO', win=0, env=opt.VISDOM.ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "softmax = torch.nn.Softmax(dim=1).cuda()\n",
    "\n",
    "pred_indices = []\n",
    "pred_scores = []\n",
    "pred_confs = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, (input, target) in enumerate(tqdm(test_loader)):\n",
    "    target = target.cuda(async=True)\n",
    "    input_var = Variable(input, volatile=True)\n",
    "\n",
    "    # compute output\n",
    "    output = model(input_var)\n",
    "    top_scores, top_indices = torch.topk(output, k=20)\n",
    "    top_indices = top_indices.data.cpu().numpy()\n",
    "    top_scores = top_scores.data.cpu().numpy()\n",
    "    \n",
    "    confs = softmax(output)\n",
    "    top_confs, _ = torch.topk(confs, k=20)\n",
    "    top_confs = top_confs.data.cpu().numpy()\n",
    "    \n",
    "    pred_indices.append(top_indices)\n",
    "    pred_scores.append(top_scores)\n",
    "    pred_confs.append(top_confs)\n",
    "\n",
    "pred_indices = np.concatenate(pred_indices)\n",
    "pred_scores = np.concatenate(pred_scores)\n",
    "pred_confs = np.concatenate(pred_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [osp.basename(image) for image, _ in test_dataset.imgs]\n",
    "\n",
    "np.savez(opt.TEST.OUTPUT, pred_indices=pred_indices, pred_scores=pred_scores,\n",
    "         pred_confs=pred_confs, images=images, checkpoint=opt.TEST.CHECKPOINT)\n",
    "logger.info(\"Results were saved to '{}'.\".format(opt.TEST.OUTPUT))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = '0.3.17'\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from sorted_folder import ImageFolder as SortedFolder\n",
    "#import argparse\n",
    "import visdom\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pprint\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from world import cfg, create_logger, AverageMeter, accuracy\n",
    "\n",
    "\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "\n",
    "opt = edict()\n",
    "\n",
    "opt.MODEL = edict()\n",
    "opt.MODEL.ARCH = 'resnet50'\n",
    "opt.MODEL.PRETRAINED = True\n",
    "opt.MODEL.IMAGE_SIZE = 256\n",
    "opt.MODEL.INPUT_SIZE = 224 # crop size\n",
    "\n",
    "opt.EXPERIMENT = edict()\n",
    "opt.EXPERIMENT.CODENAME = '2B'\n",
    "opt.EXPERIMENT.TASK = 'finetune'\n",
    "opt.EXPERIMENT.DIR = osp.join(cfg.EXPERIMENT_DIR, opt.EXPERIMENT.CODENAME)\n",
    "\n",
    "opt.LOG = edict()\n",
    "opt.LOG.LOG_FILE = osp.join(opt.EXPERIMENT.DIR, 'log_{}.txt'.format(opt.EXPERIMENT.TASK))\n",
    "\n",
    "opt.TRAIN = edict()\n",
    "opt.TRAIN.BATCH_SIZE = 32\n",
    "opt.TRAIN.SHUFFLE = True\n",
    "opt.TRAIN.WORKERS = 8\n",
    "opt.TRAIN.PRINT_FREQ = 20\n",
    "opt.TRAIN.SEED = None\n",
    "opt.TRAIN.LEARNING_RATE = 1e-4\n",
    "opt.TRAIN.LR_GAMMA = 0.5\n",
    "opt.TRAIN.LR_MILESTONES = [5, 7, 9, 10, 11, 12]\n",
    "opt.TRAIN.EPOCHS = 12\n",
    "opt.TRAIN.VAL_SUFFIX = '7c'\n",
    "opt.TRAIN.SAVE_FREQ = 1\n",
    "opt.TRAIN.RESUME = None\n",
    "\n",
    "opt.DATASET = 'recognition'\n",
    "\n",
    "opt.VISDOM = edict()\n",
    "opt.VISDOM.PORT = 8097\n",
    "opt.VISDOM.ENV = '[' + opt.DATASET + ']' + opt.EXPERIMENT.CODENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if opt.TRAIN.SEED is None:        \n",
    "    opt.TRAIN.SEED = int(time.time())\n",
    "msg = 'Use time as random seed: {}'.format(opt.TRAIN.SEED)\n",
    "print(msg)\n",
    "#logger.info(msg)\n",
    "transforms.__package__\n",
    "random.seed(opt.TRAIN.SEED)\n",
    "torch.manual_seed(opt.TRAIN.SEED)\n",
    "torch.cuda.manual_seed(opt.TRAIN.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not osp.exists(opt.EXPERIMENT.DIR):\n",
    "    os.makedirs(opt.EXPERIMENT.DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logger = create_logger(opt.LOG.LOG_FILE)\n",
    "logger.info('\\n\\nOptions:')\n",
    "logger.info(pprint.pformat(opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "DATA_INFO = cfg.DATASETS[opt.DATASET.upper()]\n",
    "\n",
    "# Data-loader of training set\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((opt.MODEL.IMAGE_SIZE)), #Smaller edge\n",
    "    transforms.RandomCrop(opt.MODEL.INPUT_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                          std = [ 0.229, 0.224, 0.225 ]),\n",
    "])\n",
    "    \n",
    "# Data-loader of testing set\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((opt.MODEL.IMAGE_SIZE)),\n",
    "    transforms.CenterCrop(opt.MODEL.INPUT_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                          std = [ 0.229, 0.224, 0.225 ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "train_dataset = SortedFolder(DATA_INFO.TRAIN_DIR, transform_train)    \n",
    "val_dataset = SortedFolder(DATA_INFO.TRAIN_DIR, transform_val)  \n",
    "\n",
    "assert(len(train_dataset.classes) == DATA_INFO.NUM_CLASSES)    \n",
    "logger.info('{} images are found for train_val'.format(len(train_dataset.imgs)))\n",
    "\n",
    "train_imgs = [(img, target) for (img, target) in train_dataset.imgs if not img[-5] in opt.TRAIN.VAL_SUFFIX]\n",
    "logger.info('{} images are used to train'.format(len(train_imgs)))\n",
    "val_imgs = [(img, target) for (img, target) in train_dataset.imgs if img[-5] in opt.TRAIN.VAL_SUFFIX]\n",
    "logger.info('{} images are used to val'.format(len(val_imgs)))\n",
    "\n",
    "\n",
    "train_dataset.samples = train_dataset.imgs = train_imgs\n",
    "val_dataset.samples = val_dataset.imgs = val_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=opt.TRAIN.BATCH_SIZE, shuffle=opt.TRAIN.SHUFFLE, num_workers=opt.TRAIN.WORKERS)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=opt.TRAIN.BATCH_SIZE, shuffle=False, num_workers=opt.TRAIN.WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create model\n",
    "if opt.MODEL.PRETRAINED:\n",
    "    logger.info(\"=> using pre-trained model '{}'\".format(opt.MODEL.ARCH ))\n",
    "    model = models.__dict__[opt.MODEL.ARCH](pretrained=True)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "#    logger.info(\"=> creating model '{}'\".format(args.arch))\n",
    "#    model = models.__dict__[opt.MODEL.ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if opt.MODEL.ARCH.startswith('resnet'):\n",
    "    assert(opt.MODEL.INPUT_SIZE % 32 == 0)\n",
    "    model.avgpool = nn.AvgPool2d(opt.MODEL.INPUT_SIZE // 32, stride=1)\n",
    "    #model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, DATA_INFO.NUM_CLASSES)\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.module.parameters(), opt.TRAIN.LEARNING_RATE)\n",
    "lr_scheduler = MultiStepLR(optimizer, opt.TRAIN.LR_MILESTONES, gamma=opt.TRAIN.LR_GAMMA, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if opt.TRAIN.RESUME is None:\n",
    "    last_epoch = 0\n",
    "    logger.info(\"Training will start from Epoch {}\".format(last_epoch+1))\n",
    "\n",
    "else:\n",
    "    last_checkpoint = torch.load(opt.TRAIN.RESUME)\n",
    "    assert(last_checkpoint['arch']==opt.MODEL.ARCH)\n",
    "    model.module.load_state_dict(last_checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(last_checkpoint['optimizer'])\n",
    "    logger.info(\"Checkpoint '{}' was loaded.\".format(opt.TRAIN.RESUME))\n",
    "    \n",
    "    last_epoch = last_checkpoint['epoch']\n",
    "    logger.info(\"Training will be resumed from Epoch {}\".format(last_checkpoint['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vis = visdom.Visdom(port=opt.VISDOM.PORT)\n",
    "vis.close()\n",
    "vis.text('HELLO', win=0, env=opt.VISDOM.ENV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_losses = []\n",
    "train_top1s = []\n",
    "test_losses = []\n",
    "test_top1s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize():\n",
    "    \n",
    "    X = np.array(range(len(train_losses))) + 1 + last_epoch\n",
    "    vis.line(\n",
    "        X=np.column_stack((X, X)), \n",
    "        Y=np.column_stack((train_losses, test_losses)), \n",
    "        win=1,\n",
    "        env=opt.VISDOM.ENV,\n",
    "        opts={\n",
    "                'title': 'loss over time',\n",
    "                'xlabel': 'epoch',\n",
    "                'ylabel': 'loss' ,\n",
    "                'legend': ['train','test']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    vis.line(\n",
    "        X=np.column_stack((X, X)), \n",
    "        Y=np.column_stack((train_top1s, test_top1s)),  \n",
    "        win=2,\n",
    "        env=opt.VISDOM.ENV,\n",
    "        opts={\n",
    "                'title': 'accuracy over time',\n",
    "                'xlabel': 'epoch',\n",
    "                'ylabel': 'accuracy (%)' ,\n",
    "                'legend': ['train','test']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pk'):\n",
    "    torch.save(state, osp.join(opt.EXPERIMENT.DIR, filename))\n",
    "    logger.info('A snapshot was saved to {}.'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    logger.info('Epoch {}'.format(epoch))\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = Variable(input)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % opt.TRAIN.PRINT_FREQ == 0:\n",
    "            logger.info('[{1}/{2}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                        'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                        epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                        data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "\n",
    "    train_losses.append(losses.avg)\n",
    "    train_top1s.append(top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = Variable(input, volatile=True)\n",
    "        target_var = Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % opt.TRAIN.PRINT_FREQ == 0:    \n",
    "            logger.info('Test: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                        'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                        i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                        top1=top1, top5=top5))\n",
    "\n",
    "\n",
    "    logger.info(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "                .format(top1=top1, top5=top5))\n",
    "\n",
    "    test_losses.append(losses.avg)\n",
    "    test_top1s.append(top1.avg)\n",
    "    \n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_prec1 = 0\n",
    "best_epoch = 0\n",
    "for epoch in range(last_epoch+1, opt.TRAIN.EPOCHS+1):\n",
    "    logger.info('-'*50)\n",
    "    lr_scheduler.step(epoch)\n",
    "    logger.info('lr: {}'.format(lr_scheduler.get_lr()))\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    prec1 = validate(test_loader, model, criterion)\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    if is_best:\n",
    "        best_epoch = epoch\n",
    "        \n",
    "    if epoch % opt.TRAIN.SAVE_FREQ == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': opt.MODEL.ARCH,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'prec1': prec1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, '{}_[{}]_{:.02f}.pk'.format(opt.MODEL.ARCH, epoch, prec1))\n",
    "    \n",
    "    if is_best:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': opt.MODEL.ARCH,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'prec1': prec1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, 'best_model.pk')       \n",
    "        \n",
    "        vis.text('Best accuracy: {} (Epoch {})'.format(prec1, epoch), win=0, env=opt.VISDOM.ENV)\n",
    "    visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "logger.info('Best accuracy for single crop: {:.02f}%'.format(best_prec1))\n",
    "#best_checkpoint_path = osp.join(opt.EXPERIMENT.DIR, 'best_model.pk')    \n",
    "#logger.info(\"Loading parameters from the best checkpoint '{}',\".format(best_checkpoint_path))\n",
    "#checkpoint = torch.load(best_checkpoint_path)\n",
    "#logger.info(\"which has a single crop accuracy {:.02f}%.\".format(checkpoint['prec1']))\n",
    "#model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_epoch = np.argmin(test_losses)\n",
    "best_loss = test_losses[best_epoch]\n",
    "plt.figure(0)\n",
    "x = np.arange(last_epoch+1, opt.TRAIN.EPOCHS+1)\n",
    "plt.plot(x, train_losses, '-+')\n",
    "plt.plot(x, test_losses, '-+')\n",
    "plt.scatter(best_epoch+1, best_loss, c='C1', marker='^', s=80)\n",
    "plt.ylim(ymin=0, ymax=5)\n",
    "plt.grid(linestyle=':')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Loss over epoch')\n",
    "plt.savefig(osp.join(opt.EXPERIMENT.DIR, 'loss_curves.png'))\n",
    "\n",
    "\n",
    "best_epoch = np.argmax(test_top1s)\n",
    "best_top1 = test_top1s[best_epoch]\n",
    "plt.figure(1)\n",
    "plt.plot(x, train_top1s, '-+')\n",
    "plt.plot(x, test_top1s, '-+')\n",
    "plt.scatter(best_epoch+1, best_top1, c='C1', marker='^', s=80)\n",
    "plt.ylim(ymin=0, ymax=100)\n",
    "plt.grid(linestyle=':')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy (%)')\n",
    "plt.title('accuracy over epoch')\n",
    "plt.savefig(osp.join(opt.EXPERIMENT.DIR, 'accuracy_curves.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])\n",
    "# x = np.array([[False, True, True], [False, True, False], [True, True, False]])\n",
    "a = np.arange(10)\n",
    "print (np.nonzero(a == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    \"\"\"Dataset that on each iteration provides an anchor image,\n",
    "    a positive match, and a negative match, in that order.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.base_dataset = dataset\n",
    "        \n",
    "        #find index of each class\n",
    "        class_indices = []\n",
    "        image_classes = np.array([x[1] for x in self.base_dataset.imgs])\n",
    "        num_classes = len(self.base_dataset.classes)\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            indices = np.nonzero(image_classes == c)[0]\n",
    "            class_indices.append(indices)\n",
    "            \n",
    "        #generate balanced pairs\n",
    "        self.trip_indexes = np.zeros((len(self.base_dataset), 3), dtype=int)\n",
    "        i = 0\n",
    "        for c in range(num_classes):\n",
    "            num_examples = len(class_indices[c])\n",
    "            for j in range(num_examples):\n",
    "                # choose another class at random\n",
    "                neg_cls = random.randint(0, num_classes-2)\n",
    "                if neg_cls >= c:\n",
    "                    neg_cls += 1\n",
    "                neg_idx = random.randint(0, len(class_indices[neg_cls])-1)\n",
    "                \n",
    "                # choose another picture of the same class at random\n",
    "                pos_idx = random.randint(0, num_examples-2)\n",
    "                if pos_idx >= j:\n",
    "                    pos_idx += 1\n",
    "                self.trip_indexes[i,:] = [class_indices[c][j],\n",
    "                                          class_indices[c][pos_idx],\n",
    "                                          class_indices[neg_cls][neg_idx]]\n",
    "                i += 1\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" Output is a 3 x C x H x W tensor, and [1,0] indicating positive and negative match\n",
    "        \"\"\"\n",
    "        idxs = self.trip_indexes[index]\n",
    "        \n",
    "        triplet = []\n",
    "        for idx in idxs:\n",
    "            triplet.append(self.base_dataset[idx][0])\n",
    "            \n",
    "        return torch.stack(triplet, dim=0), torch.tensor([1, 0])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trip_indexes)\n",
    "    \n",
    "input_size = 224\n",
    "data_dir = \"/home/kylecshan/data/images224/train_ms2000_v3/\"\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) \n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "for x in ['train', 'val']:\n",
    "    image_datasets[x] = TripletDataset(image_datasets[x])\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=4)\n",
    "                    for x in ['train', 'val']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in dataloaders_dict['train']:\n",
    "    print (inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class Pool(nn.Module):\n",
    "    def __init__(self, batch = 8):\n",
    "        super(Pool,self).__init__()\n",
    "        self.batch = batch\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.adaptive_avg_pool2d(x, (1, 1)).view(self.batch, -1)\n",
    "        return out\n",
    "\n",
    "model_ft = models.densenet169(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 2000)\n",
    "\n",
    "features = list(model_ft.children())[:-1]\n",
    "features.append(nn.ReLU(inplace=True))\n",
    "features.append(Pool())\n",
    "features.append(list(model_ft.children())[-1])\n",
    "model_ft = nn.Sequential(*features)\n",
    "\n",
    "print (features)\n",
    "tensor = torch.ones((8, 3, 224, 224))\n",
    "out = model_ft(tensor)\n",
    "\n",
    "print (out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
